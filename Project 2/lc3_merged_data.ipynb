{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LC3 DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analize the relation of the compressive strength of LC3 with the clay used for its elaboration properties. For this purpose we utilize the dataset given by the Constructions Materials Laboratory at EPFL. This dataset consists of different measures of compressive strength for different types of LC3 cement in which the clay used for their ellaboration varies. We have also several clay properties measured and the objetive is finding the relation of the compressive strength (CS) with these for a deeper understanding of key elements in LC3 cement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lc3_implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file path (can be also an excel .xlsx)\n",
    "DATA_PATH = './data/data_merged.ods'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hide this in lc3_implementations or in lc3_helpers!\n",
    "\n",
    "# Read data skipping the first row and considering also '-' as NaN\n",
    "data = pd.read_excel(DATA_PATH, skiprows=[0], na_values=['-'])\n",
    "\n",
    "# We rename some columns for having an easier reference\n",
    "data.rename(columns = {'Calcined kaolinite content (%)':'Kaolinite_content'}, inplace = True)\n",
    "data.rename(columns = {'Dv,50 (µm)':'Dv50'                                 }, inplace = True)\n",
    "data.rename(columns = {'BET Specific surface (m2/g)':'BET_specific_surface'}, inplace = True)\n",
    "data.rename(columns = {'Span (-)':'span'                                   }, inplace = True)\n",
    "\n",
    "data.rename(columns = {'STD'  : 'STD_1D'}, inplace = True)\n",
    "data.rename(columns = {'STD.1': 'STD_3D'}, inplace = True)\n",
    "data.rename(columns = {'STD.2': 'STD_7D'}, inplace = True)\n",
    "data.rename(columns = {'STD.3':'STD_28D'}, inplace = True)\n",
    "data.rename(columns = {'STD.4':'STD_90D'}, inplace = True)\n",
    "\n",
    "# Sorting allows us to plot functions more easily\n",
    "data = data.sort_values('Kaolinite_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for seeing data loaded\n",
    "#data               # Get data\n",
    "#data.describe()    # Get data general information\n",
    "#data.columns       # Get data features names\n",
    "#data.corr()        # Get correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take kaolinite content\n",
    "x = data['Kaolinite_content'].values \n",
    "\n",
    "# Take compression strengths\n",
    "y1  = data[ \"1D\"].values\n",
    "y3  = data[ \"3D\"].values\n",
    "y7  = data[ \"7D\"].values\n",
    "y28 = data[\"28D\"].values\n",
    "y90 = data[\"90D\"].values\n",
    "\n",
    "# Measures at 90 days have missing values (4 in total)\n",
    "x90 =   x[np.logical_not(np.isnan(y90))]\n",
    "y90 = y90[np.logical_not(np.isnan(y90))]\n",
    "\n",
    "# Take standard deviations\n",
    "#z1  = data[ \"STD_1D\"].values\n",
    "#z3  = data[ \"STD_3D\"].values\n",
    "#z7  = data[ \"STD_7D\"].values\n",
    "#z28 = data[\"STD_28D\"].values\n",
    "#z90 = data[\"STD_90D\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show points using matplotlib.pyplot library\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plt.plot(x,y1,'c^',x,y3,'bs',x,y7,'r^',x,y28,'go', x90,y90,'m^')\n",
    "plt.xlabel('%Kaolinite Content')\n",
    "plt.ylabel('Compressive Strenght')\n",
    "\n",
    "d1_patch  = mpatches.Patch(color='cyan',      label='After  1 day')\n",
    "d3_patch  = mpatches.Patch(color='blue',      label='After  3 days')\n",
    "d7_patch  = mpatches.Patch(color='red',       label='After  7 days')\n",
    "d28_patch = mpatches.Patch(color='darkgreen', label='After 28 days')\n",
    "d90_patch = mpatches.Patch(color='purple',    label='After 90 days')\n",
    "plt.legend(handles=[d1_patch,d3_patch,d7_patch,d28_patch,d90_patch])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sight analysis:**\n",
    "\n",
    "* **CS Day 1:** Almost constant, it curves from kaolinite content 50%, try degree two feature expansion.\n",
    "* **CS Day 3:** Sparse points, we need to add another feature and maybe try also feature expansion.\n",
    "* **CS Day 7:** The straight line is quite clear, we can try adding another feature for avoiding sparsification.\n",
    "* **CS Day 28:** Straight line until 40% kaolinite content, then it curves. Feature expansion is needed as well as another feature for reducing sparsification.\n",
    "* **CS Day 90:** Totally analogous than the day 28 data.\n",
    "\n",
    "\n",
    "**Observations and next steps:**\n",
    "* Maybe it would be interesting to have a predictor of the compression strength at 90 days (at time=infinity) knowing the compression strength before.\n",
    "* In feature augmentation never go further than degree two, the curve is clearly always increasing.\n",
    "* When having models involving only one or two features it's going to be important to plot for checking correctness.\n",
    "* We have to search also mathematical measurements for the correctness of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have measures of 21 features/properties of the clays. Which are the (cor)relations among them? Which are the most important for predicting the compression strength? Are there redundancies?  We first try to answer this question by analyzing the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to hightlight high correlated cells in red\n",
    "def highlight_high_correlations(cell):\n",
    "    return 'background-color: %s' % ('red' if (cell != 1 and abs(cell) > CORRELATION_THRESHOLD) else 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation between clays properties themselves\n",
    "CORRELATION_THRESHOLD = 0.6\n",
    "\n",
    "corr_matrix = data.corr()[10:].iloc[:, 10:]\n",
    "corr_matrix.style.applymap(highlight_high_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation between Compression Strength measurements and clays properties\n",
    "CORRELATION_THRESHOLD = 0.65\n",
    "\n",
    "corr_matrix = data.corr()[10:].iloc[:, [0,2,4,6,8]]\n",
    "corr_matrix.style.applymap(highlight_high_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between standard deviations of measurements and clays properties\n",
    "CORRELATION_THRESHOLD = 0.2\n",
    "\n",
    "corr_matrix = data.corr()[10:].iloc[:, [1,3,5,7,9]]\n",
    "corr_matrix.style.applymap(highlight_high_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sight analysis:**\n",
    "\n",
    "* Several important correlations between features, be aware of this when chosing features for our model to avoid redundancy.\n",
    "* Compression strength can be predicted quite good with only the Kaolinite content, the relation is clear.\n",
    "* At first sight there is no clear evidence of any feature being behind the standard deviation/variability of lc3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPRESSION STRENGTH (CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the kaolinite content is the most predictive feature that we have. We are going to start creating simple linear regression models and then, following the appreciations obtained by visualizing the data, we are going to create non-linear models based on the kaolinite content for better fitting the data distribution as well as models with more features for avoiding data sparsification.\n",
    "\n",
    "Two metrics are going to be extremely important here:\n",
    "* **R square:** Is giving us a measurement of how good is our model (the closer to 1.0 the better). \n",
    "* **Validation score:** Is going to let us control overfitting. Improving R² means nothing if validation is worse. We'll use mean squared error with Leave One Out cross validation to estimate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove outlier in y1 data?\n",
    "# TODO: Idea for the report, removing pesimist outliers is not a good idea in our project!\n",
    "# TODO: Add OPC compression strength values for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear models based on the kaolinite content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leave_one_out_validation(x.reshape(-1,1), y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_validation(x.reshape(-1,1), y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leave_one_out_validation(x.reshape(-1,1), y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_validation(x.reshape(-1,1), y28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leave_one_out_validation(x90.reshape(-1,1), y90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sight analysis:**\n",
    "\n",
    "* There is few more we can improve at the 7th day using only the kaolinite content, data distribution is quite linear.\n",
    "* For 1st and 3rd day the problem is more the sparsification of the points than the lack of expresivity of the model.\n",
    "* For 28th and 90th day until 40% of kaolinite content the compression strength increases linearly and then estabilizes. Makes sense a non-linear model.\n",
    "* It doesn't make sense in any model a degree 3 regression model, compression strength increases with kaolinite content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-linear models based on the kaolinite content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_2 = Kaolinite content, (Kaolinite content)^2\n",
    "x_2   = np.array([x, x**2]).T\n",
    "x90_2 = np.array([x90,x90*x90]).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leave_one_out_validation(x_2, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_validation(x_2, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_validation(x_2, y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leave_one_out_validation(x_2, y28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leave_one_out_validation(x90_2, y90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sight analysis:**\n",
    "\n",
    "* Expected results, better models obtained for 28th and 90th day compression strength obtained.\n",
    "* We might be experiencing overfitting with this model for 1st and 3rd day measurements because we're not increasing the compressive strength with the increase of calonita for small contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen the importance and the clear relation of the Kaolinite conent with the compression strength and, we have seen also that the models involving only kaolinite content have their limitations (because of data sparsification). For achieving better results we have to add more modelation expressiveness by adding other variables to our model (new features or other artificially created) and, since the data distribution makes us think that linear regression models with the kaolinite content in degree three or more lead to overfitting, the best choice is adding new features.\n",
    "\n",
    "Again, for avoiding overfitting with the few data we have we can't add several features so we have to decide well which is the best feature for complementing the kaolinite content. That's is the question we try to solve in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are realiable? Those with more than RELIABLE_THRESHOLD measurements\n",
    "RELIABLE_THRESHOLD = 45\n",
    "\n",
    "features = data.columns[14:]\n",
    "reliable_features = [f for f in features if data[f].describe()[0] >= RELIABLE_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the reliable features, with enough points to rely\n",
    "# reliable_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: It would be nice to highlight maximums of R2 and minimums of MSE cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection(data, reliable_features, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_selection(data, features, print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression models based on the kaolinite content and other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the results obtained in the feature selection part, here we are creating and analyzing the models done with the kaolinite conent (in degree one and two) as well as other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:Create a function that given a feature and a day prints res.summary() or returns res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Day 1 \n",
    "mod = smf.ols(formula='day_1 ~ Kaolinite_content + Kaolinite_content_square + Dv50', data=get_model_data(data, 'Dv50','1D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 1 \n",
    "mod = smf.ols(formula='day_1 ~ Kaolinite_content + Kaolinite_content_square + CaO', data=get_model_data(data,'CaO','1D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3\n",
    "mod = smf.ols(formula='day_3 ~ Kaolinite_content + Kaolinite_content_square + Dv50', data=get_model_data(data,'Dv50','3D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 3\n",
    "mod = smf.ols(formula='day_3 ~ Kaolinite_content + Kaolinite_content_square + CaO', data=get_model_data(data,'CaO','3D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 7\n",
    "mod = smf.ols(formula='day_7 ~ Kaolinite_content + Kaolinite_content_square + BET_specific_surface', data=get_model_data(data, 'BET_specific_surface','7D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 28\n",
    "mod = smf.ols(formula='day_2 ~ Kaolinite_content + Kaolinite_content_square + BET_specific_surface', data=get_model_data(data, 'BET_specific_surface','28D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 28\n",
    "mod = smf.ols(formula='day_2 ~ Kaolinite_content + Kaolinite_content_square + TiO2', data=get_model_data(data, 'TiO2','28D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 90\n",
    "mod = smf.ols(formula='day_9 ~ Kaolinite_content + Kaolinite_content_square + BET_specific_surface', data=get_model_data(data, 'BET_specific_surface','90D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Day 90\n",
    "mod = smf.ols(formula='day_9 ~ Kaolinite_content + Kaolinite_content_square + TiO2', data=get_model_data(data, 'TiO2','90D'))\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence analysis for the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know our model (function depending on the features provided) as well as some metrics to have an idea of how well our model fits our data (R2) and how is it behaving in practice with new data (MSE). The objetive of this section is to provide a more mathematical analysis of the confidence we can expect from our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy examples for putting things into practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with the Kaolinite content based model for compression strength at day 90 to exemplify the tools and techniques we can use to estimate confidence intervals in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get_model_data should generalize this behavior for giving kaolinite in degree one and 2 and a given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_28 = data[['Kaolinite_content', '28D']].copy()\n",
    "data_28.insert(1, 'Kaolinite_content_square', data['Kaolinite_content']**2, True)\n",
    "data_28 = data_28.dropna()\n",
    "data_28.rename(columns = {'28D' : 'day_28'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Day 28\n",
    "#mod = smf.ols(formula='day_28 ~ Kaolinite_content + Kaolinite_content_square', data=data_28)\n",
    "#np.random.seed(2)\n",
    "#res = mod.fit()\n",
    "#res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confidence_intervals(data_28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_90 = data[['Kaolinite_content', '90D']].copy()\n",
    "data_90.insert(1, 'Kaolinite_content_square', data['Kaolinite_content']**2, True)\n",
    "data_90 = data_90.dropna()\n",
    "data_90.rename(columns = {'90D' : 'day_90'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 90\n",
    "#mod = smf.ols(formula='day_90 ~ Kaolinite_content + Kaolinite_content_square', data=data_90)\n",
    "#np.random.seed(2)\n",
    "#res = mod.fit()\n",
    "#res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confidence_intervals(data_90, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First sight analysis:**\n",
    "\n",
    "* We can't afford confidence intervals of such a high precission with such a lack of points, specially for high kaolinite contents.\n",
    "* However, this worths a try after adding all the points from the second excel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* How to deal with small datasets:\\\n",
    "https://medium.com/rants-on-machine-learning/what-to-do-with-small-data-d253254d1a89\n",
    "\n",
    "* Feature engineering: \\\n",
    "https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n",
    "\n",
    "* Feature selection: \\\n",
    "https://en.wikipedia.org/wiki/Feature_selection \\\n",
    "https://machinelearningmastery.com/an-introduction-to-feature-selection/ \\\n",
    "https://machinelearningmastery.com/feature-selection-machine-learning-python/ \\\n",
    "https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/ \\\n",
    "https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "\n",
    "* Linear regression with python: \\\n",
    "https://realpython.com/linear-regression-in-python/ \n",
    "\n",
    "* Confidence estimation: \\\n",
    "https://www.puneetarora2000.com/2020/01/data-interpretation-understanding-ols.html \\\n",
    "https://medium.com/@jyotiyadav99111/statistics-how-should-i-interpret-results-of-ols-3bde1ebeec01 \\\n",
    "https://www.statsmodels.org/stable/regression.html \\\n",
    "https://www.datarobot.com/blog/ordinary-least-squares-in-python/ \\\n",
    "https://online.stat.psu.edu/stat415/lesson/7/7.5 \\\n",
    "https://tungmphung.com/confidence-intervals-for-linear-regression-coefficients/ \\\n",
    "https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
